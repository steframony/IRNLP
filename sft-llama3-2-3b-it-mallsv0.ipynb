{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caratteristiche del notebook\n",
    "\n",
    "- System_prompt presente = No\n",
    "- Dataset usato = MALLS_V0\n",
    "- Epoche = 3\n",
    "- Fine Tuning eseguito = Si - Repo -> francescoocurcio/new_llama3.2-3B-log-ftn-malls-3epoch_10k-sysprompt_no\n",
    "- Addestrato solo sulle risposte = No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importazione delle librerie e definizione delle costanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:36:09.887530Z",
     "iopub.status.busy": "2025-05-10T13:36:09.886984Z",
     "iopub.status.idle": "2025-05-10T13:40:09.603283Z",
     "shell.execute_reply": "2025-05-10T13:40:09.602227Z",
     "shell.execute_reply.started": "2025-05-10T13:36:09.887508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pip3-autoremove\n",
    "!pip-autoremove torch torchvision torchaudio -y\n",
    "!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:40:36.354128Z",
     "iopub.status.busy": "2025-05-10T13:40:36.353334Z",
     "iopub.status.idle": "2025-05-10T13:41:21.373798Z",
     "shell.execute_reply": "2025-05-10T13:41:21.373187Z",
     "shell.execute_reply.started": "2025-05-10T13:40:36.354098Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 13:40:53.945094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746884454.369512      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746884454.484903      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "# IMPORT DELLE LIBRERIE\n",
    "#########################\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  # Mostra tutte le colonne\n",
    "pd.set_option('display.width', None)        # Non tronca l'output a una larghezza fissa\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from datasets import load_dataset\n",
    "from IPython.display import display\n",
    "from unsloth import FastLanguageModel, to_sharegpt\n",
    "from unsloth.chat_templates import get_chat_template, standardize_sharegpt\n",
    "from datasets import Dataset\n",
    "\n",
    "#########################\n",
    "# COSTANTI\n",
    "#########################\n",
    "\n",
    "MAX_SEQ_LENGTH = 2048\n",
    "DTYPE = None\n",
    "LOAD_IN_4BIT = True\n",
    "\n",
    "OUTPUT_REPO = \"francescoocurcio/new_llama3.2-3B-log-ftn-malls-3epoch_10k-sysprompt_no\"\n",
    "SAVE_DIRECTORY = \"/kaggle/working/new_llama3.2-3B-log-ftn-malls-3epoch_10k-sysprompt_no\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:41:26.559394Z",
     "iopub.status.busy": "2025-05-10T13:41:26.558669Z",
     "iopub.status.idle": "2025-05-10T13:41:27.325611Z",
     "shell.execute_reply": "2025-05-10T13:41:27.324700Z",
     "shell.execute_reply.started": "2025-05-10T13:41:26.559369Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "The token `UNIVERSAL_TOKEN` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `UNIVERSAL_TOKEN`\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selezione e configurazione del modello: Llama3.2 3B Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:41:31.473027Z",
     "iopub.status.busy": "2025-05-10T13:41:31.472677Z",
     "iopub.status.idle": "2025-05-10T13:43:09.018985Z",
     "shell.execute_reply": "2025-05-10T13:43:09.018333Z",
     "shell.execute_reply.started": "2025-05-10T13:41:31.472998Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Llama patching. Transformers: 4.51.1.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.5.1+cu121. CUDA: 7.5. CUDA Toolkit: 12.1. Triton: 3.1.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16234f0fbfd49c9bed2f2e59f4bffe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.35G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192685a80eee44d1a210a773ff1bd97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f26ba1aaad2458d842281e91df4d7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945a40873c924ad58dbc4f9f92d2a55d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9220a68d9eaf4caa95b70732d9b0a943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.4.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length = MAX_SEQ_LENGTH,\n",
    "    dtype = DTYPE,\n",
    "    load_in_4bit = LOAD_IN_4BIT\n",
    "    # token = \"hf...\" #Use one if using gated models like meta-llama/Llama....\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "#PEFT = Parameter Efficient Fine Tuning\n",
    "model = FastLanguageModel.get_peft_model( #Modello quantizzato\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 32,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 42,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:43:18.242865Z",
     "iopub.status.busy": "2025-05-10T13:43:18.242237Z",
     "iopub.status.idle": "2025-05-10T13:43:20.125523Z",
     "shell.execute_reply": "2025-05-10T13:43:20.124837Z",
     "shell.execute_reply.started": "2025-05-10T13:43:18.242840Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107da538742941228222068043130c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03889ded65cb4850a27c032b10c55a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MALLS-v0.1-train.json:   0%|          | 0.00/6.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab9844899e34c09a969f28a88a23df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MALLS-v0.1-test.json:   0%|          | 0.00/231k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a67b9308039487ca41a986132cabe69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/27284 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "869528d51b424511b569f48073fa694d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOL</th>\n",
       "      <th>NL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>âˆ€x (WritingInstrument(x) âˆ§ ThinCylindricalBody(x) âˆ§ ContainsInk(x) âˆ§ UsesSmallBall(x) âˆ§ TransfersInkToPaper(x) â†’ BallpointPen(x))</td>\n",
       "      <td>A writing instrument that has a thin, cylindrical body, contains ink, and uses a small ball to transfer ink to paper is a ballpoint pen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>âˆ€x (Machine(x) âˆ§ PerformsTasksAutonomously(x) âˆ§ WithoutHumanIntervention(x) â†’ Robot(x))</td>\n",
       "      <td>A machine that can perform tasks autonomously without human intervention is a robot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>âˆ€xâˆ€yâˆ€z (Farmer(x) âˆ§ Crop(y) âˆ§ Livestock(z) âˆ§ Farm(w) â†’ GrowsAndRaises(x, y, z, w))</td>\n",
       "      <td>A farmer grows crops and raises livestock on a farm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>âˆ€x (Engine(x) âˆ§ BurnsFuelInCombustionChamber(x) âˆ§ GeneratesMechanicalPower(x) â†’ InternalCombustionEngine(x))</td>\n",
       "      <td>An engine is an internal combustion engine if it generates mechanical power by burning fuel in a combustion chamber.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>âˆ€x (Airplane(x) â†’ CanFly(x))</td>\n",
       "      <td>If a vehicle is an airplane, it can fly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>âˆ€x (Parent(x) â†” âˆƒy (Child(y) âˆ§ HasChild(x, y)))</td>\n",
       "      <td>A person is a parent if they have a child.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>âˆ€x (Cat(x) âˆ§ Hungry(x) â†’ Meows(x))</td>\n",
       "      <td>Cats meow when they are hungry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>âˆ€x âˆ€y âˆ€z (Bicycle(x) â†’ Wheels(x, 2)) âˆ§ (Tricycle(y) â†’ Wheels(y, 3)) âˆ§ (Unicycle(z) â†’ Wheels(z, 1))</td>\n",
       "      <td>A bicycle has two wheels, a tricycle has three wheels, and a unicycle has one wheel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>âˆ€x (Bike(x) âˆ§ (FlatTire(x) âˆ¨ BrokenChain(x)) â†’ NeedsRepair(x))</td>\n",
       "      <td>A bike must have at least one flat tire or a broken chain to be considered in need of repair.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>âˆƒx âˆƒy (Dog(x) âˆ§ Cat(y) âˆ§ Chases(x, y))</td>\n",
       "      <td>A dog chases a cat.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    FOL  \\\n",
       "0     âˆ€x (WritingInstrument(x) âˆ§ ThinCylindricalBody(x) âˆ§ ContainsInk(x) âˆ§ UsesSmallBall(x) âˆ§ TransfersInkToPaper(x) â†’ BallpointPen(x))   \n",
       "1                                               âˆ€x (Machine(x) âˆ§ PerformsTasksAutonomously(x) âˆ§ WithoutHumanIntervention(x) â†’ Robot(x))   \n",
       "2                                                    âˆ€xâˆ€yâˆ€z (Farmer(x) âˆ§ Crop(y) âˆ§ Livestock(z) âˆ§ Farm(w) â†’ GrowsAndRaises(x, y, z, w))   \n",
       "3                          âˆ€x (Engine(x) âˆ§ BurnsFuelInCombustionChamber(x) âˆ§ GeneratesMechanicalPower(x) â†’ InternalCombustionEngine(x))   \n",
       "4                                                                                                          âˆ€x (Airplane(x) â†’ CanFly(x))   \n",
       "...                                                                                                                                 ...   \n",
       "9995                                                                                    âˆ€x (Parent(x) â†” âˆƒy (Child(y) âˆ§ HasChild(x, y)))   \n",
       "9996                                                                                                 âˆ€x (Cat(x) âˆ§ Hungry(x) â†’ Meows(x))   \n",
       "9997                                 âˆ€x âˆ€y âˆ€z (Bicycle(x) â†’ Wheels(x, 2)) âˆ§ (Tricycle(y) â†’ Wheels(y, 3)) âˆ§ (Unicycle(z) â†’ Wheels(z, 1))   \n",
       "9998                                                                     âˆ€x (Bike(x) âˆ§ (FlatTire(x) âˆ¨ BrokenChain(x)) â†’ NeedsRepair(x))   \n",
       "9999                                                                                             âˆƒx âˆƒy (Dog(x) âˆ§ Cat(y) âˆ§ Chases(x, y))   \n",
       "\n",
       "                                                                                                                                            NL  \n",
       "0     A writing instrument that has a thin, cylindrical body, contains ink, and uses a small ball to transfer ink to paper is a ballpoint pen.  \n",
       "1                                                         A machine that can perform tasks autonomously without human intervention is a robot.  \n",
       "2                                                                                         A farmer grows crops and raises livestock on a farm.  \n",
       "3                         An engine is an internal combustion engine if it generates mechanical power by burning fuel in a combustion chamber.  \n",
       "4                                                                                                     If a vehicle is an airplane, it can fly.  \n",
       "...                                                                                                                                        ...  \n",
       "9995                                                                                                A person is a parent if they have a child.  \n",
       "9996                                                                                                           Cats meow when they are hungry.  \n",
       "9997                                                      A bicycle has two wheels, a tricycle has three wheels, and a unicycle has one wheel.  \n",
       "9998                                             A bike must have at least one flat tire or a broken chain to be considered in need of repair.  \n",
       "9999                                                                                                                       A dog chases a cat.  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = load_dataset(\"yuan-yang/MALLS-v0\", split=\"train\").to_pandas().sample(n=10000, random_state=42).reset_index(drop=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:43:22.362406Z",
     "iopub.status.busy": "2025-05-10T13:43:22.361616Z",
     "iopub.status.idle": "2025-05-10T13:43:22.532702Z",
     "shell.execute_reply": "2025-05-10T13:43:22.531795Z",
     "shell.execute_reply.started": "2025-05-10T13:43:22.362378Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4c8ce5d20c4b5d9d7e754c9d91c1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging columns:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e5cdac8abf4679a34444f64338c2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting to ShareGPT:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversations': [{'from': 'human', 'value': \"Convert the following Natural Language statement into a First-Order Logic formula.:\\n('A writing instrument that has a thin, cylindrical body, contains ink, and uses a small ball to transfer ink to paper is a ballpoint pen.',)\"}, {'from': 'gpt', 'value': 'âˆ€x (WritingInstrument(x) âˆ§ ThinCylindricalBody(x) âˆ§ ContainsInk(x) âˆ§ UsesSmallBall(x) âˆ§ TransfersInkToPaper(x) â†’ BallpointPen(x))'}]}\n"
     ]
    }
   ],
   "source": [
    "from unsloth import to_sharegpt\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "dataset = to_sharegpt(\n",
    "    dataset,\n",
    "    merged_prompt = \"Convert the following Natural Language statement into a First-Order Logic formula.[[:\\n{NL}]]\",\n",
    "    output_column_name = \"FOL\",\n",
    "    conversation_extension = 1, #Select more to handle longer conversations\n",
    ")\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opzione di aggiunta per il system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#system_message = {\n",
    "#    \"from\": \"system\",\n",
    "#    \"value\": (\n",
    "#        \"You are a math expert. You will be given a mathematical problem to solve. \"\n",
    "#        \"Your aim is to first provide a step-by-step explanation of the solution \"\n",
    "#        \"(integrating the formulae in LaTeX syntax) and then to conclude with a clear and concise final answer.\"\n",
    "#    )\n",
    "#}\n",
    "\n",
    "# Aggiungilo all'inizio di ogni conversazione\n",
    "#def add_system_message(example):\n",
    "#    conversation = example[\"conversations\"]\n",
    "#    return {\n",
    "#        \"conversations\": [system_message] + conversation\n",
    "#    }\n",
    "\n",
    "# Applica la funzione a tutto il dataset\n",
    "#dataset = dataset.map(add_system_message)\n",
    "#print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Costruzione dataset finale conversazionale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:43:26.037258Z",
     "iopub.status.busy": "2025-05-10T13:43:26.036439Z",
     "iopub.status.idle": "2025-05-10T13:43:26.795695Z",
     "shell.execute_reply": "2025-05-10T13:43:26.794920Z",
     "shell.execute_reply.started": "2025-05-10T13:43:26.037222Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3088360bc3174e2c83237e3ef4d87b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Standardizing formats (num_proc=4):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['conversations'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "{'conversations': [{'content': \"Convert the following Natural Language statement into a First-Order Logic formula.:\\n('A writing instrument that has a thin, cylindrical body, contains ink, and uses a small ball to transfer ink to paper is a ballpoint pen.',)\", 'role': 'user'}, {'content': 'âˆ€x (WritingInstrument(x) âˆ§ ThinCylindricalBody(x) âˆ§ ContainsInk(x) âˆ§ UsesSmallBall(x) âˆ§ TransfersInkToPaper(x) â†’ BallpointPen(x))', 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import standardize_sharegpt\n",
    "dataset = standardize_sharegpt(dataset)\n",
    "\n",
    "print(dataset)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:43:29.216848Z",
     "iopub.status.busy": "2025-05-10T13:43:29.216135Z",
     "iopub.status.idle": "2025-05-10T13:43:30.162689Z",
     "shell.execute_reply": "2025-05-10T13:43:30.161862Z",
     "shell.execute_reply.started": "2025-05-10T13:43:29.216819Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model does not have a padding token! Will use pad_token = <|finetune_right_pad_id|>.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1741539c79ad4152bf5827a26e851c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nConvert the following Natural Language statement into a First-Order Logic formula.:\\n('A writing instrument that has a thin, cylindrical body, contains ink, and uses a small ball to transfer ink to paper is a ballpoint pen.',)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nâˆ€x (WritingInstrument(x) âˆ§ ThinCylindricalBody(x) âˆ§ ContainsInk(x) âˆ§ UsesSmallBall(x) âˆ§ TransfersInkToPaper(x) â†’ BallpointPen(x))<|eot_id|>\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"llama-3.1\",\n",
    ")\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
    "    return { \"text\" : texts, }\n",
    "pass\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True)\n",
    "dataset[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:43:32.409711Z",
     "iopub.status.busy": "2025-05-10T13:43:32.409375Z",
     "iopub.status.idle": "2025-05-10T13:43:32.414636Z",
     "shell.execute_reply": "2025-05-10T13:43:32.413849Z",
     "shell.execute_reply.started": "2025-05-10T13:43:32.409689Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|finetune_right_pad_id|>\n",
      "128004\n",
      "right\n",
      "<|eot_id|>\n",
      "128009\n",
      "left\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.pad_token)\n",
    "print(tokenizer.pad_token_id)\n",
    "print(tokenizer.padding_side)\n",
    "#Anche dopo aver cambiato inizialmente queste operazioni il tokenizer a fronte delle\n",
    "#operazioni eseguite Ã¨ come se eseguisse una sorta di riformattazione\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "print(tokenizer.pad_token)\n",
    "print(tokenizer.pad_token_id)\n",
    "print(tokenizer.padding_side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:43:34.595021Z",
     "iopub.status.busy": "2025-05-10T13:43:34.594302Z",
     "iopub.status.idle": "2025-05-10T13:43:34.603395Z",
     "shell.execute_reply": "2025-05-10T13:43:34.602781Z",
     "shell.execute_reply.started": "2025-05-10T13:43:34.594996Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000 | Token ID: 128000 | Token: '<|begin_of_text|>'\n",
      "001 | Token ID: 128000 | Token: '<|begin_of_text|>'\n",
      "002 | Token ID: 128006 | Token: '<|start_header_id|>'\n",
      "003 | Token ID:   9125 | Token: 'system'\n",
      "004 | Token ID: 128007 | Token: '<|end_header_id|>'\n",
      "005 | Token ID:    271 | Token: 'ÄŠÄŠ'\n",
      "006 | Token ID:  38766 | Token: 'Cut'\n",
      "007 | Token ID:   1303 | Token: 'ting'\n",
      "008 | Token ID:  33025 | Token: 'Ä Knowledge'\n",
      "009 | Token ID:   2696 | Token: 'Ä Date'\n",
      "010 | Token ID:     25 | Token: ':'\n",
      "011 | Token ID:   6790 | Token: 'Ä December'\n",
      "012 | Token ID:    220 | Token: 'Ä '\n",
      "013 | Token ID:   2366 | Token: '202'\n",
      "014 | Token ID:     18 | Token: '3'\n",
      "015 | Token ID:    198 | Token: 'ÄŠ'\n",
      "016 | Token ID:  15724 | Token: 'Today'\n",
      "017 | Token ID:   2696 | Token: 'Ä Date'\n",
      "018 | Token ID:     25 | Token: ':'\n",
      "019 | Token ID:    220 | Token: 'Ä '\n",
      "020 | Token ID:   1627 | Token: '26'\n",
      "021 | Token ID:   5887 | Token: 'Ä July'\n",
      "022 | Token ID:    220 | Token: 'Ä '\n",
      "023 | Token ID:   2366 | Token: '202'\n",
      "024 | Token ID:     19 | Token: '4'\n",
      "025 | Token ID:    271 | Token: 'ÄŠÄŠ'\n",
      "026 | Token ID: 128009 | Token: '<|eot_id|>'\n",
      "027 | Token ID: 128006 | Token: '<|start_header_id|>'\n",
      "028 | Token ID:    882 | Token: 'user'\n",
      "029 | Token ID: 128007 | Token: '<|end_header_id|>'\n",
      "030 | Token ID:    271 | Token: 'ÄŠÄŠ'\n",
      "031 | Token ID:  12281 | Token: 'Convert'\n",
      "032 | Token ID:    279 | Token: 'Ä the'\n",
      "033 | Token ID:   2768 | Token: 'Ä following'\n",
      "034 | Token ID:  18955 | Token: 'Ä Natural'\n",
      "035 | Token ID:  11688 | Token: 'Ä Language'\n",
      "036 | Token ID:   5224 | Token: 'Ä statement'\n",
      "037 | Token ID:   1139 | Token: 'Ä into'\n",
      "038 | Token ID:    264 | Token: 'Ä a'\n",
      "039 | Token ID:   5629 | Token: 'Ä First'\n",
      "040 | Token ID:     12 | Token: '-'\n",
      "041 | Token ID:   4531 | Token: 'Order'\n",
      "042 | Token ID:  37201 | Token: 'Ä Logic'\n",
      "043 | Token ID:  15150 | Token: 'Ä formula'\n",
      "044 | Token ID:     13 | Token: '.'\n",
      "045 | Token ID:    512 | Token: ':ÄŠ'\n",
      "046 | Token ID:    493 | Token: \"('\"\n",
      "047 | Token ID:     32 | Token: 'A'\n",
      "048 | Token ID:   4477 | Token: 'Ä writing'\n",
      "049 | Token ID:  14473 | Token: 'Ä instrument'\n",
      "050 | Token ID:    430 | Token: 'Ä that'\n",
      "051 | Token ID:    706 | Token: 'Ä has'\n",
      "052 | Token ID:    264 | Token: 'Ä a'\n",
      "053 | Token ID:  15792 | Token: 'Ä thin'\n",
      "054 | Token ID:     11 | Token: ','\n",
      "055 | Token ID:  79610 | Token: 'Ä cylindrical'\n",
      "056 | Token ID:   2547 | Token: 'Ä body'\n",
      "057 | Token ID:     11 | Token: ','\n",
      "058 | Token ID:   5727 | Token: 'Ä contains'\n",
      "059 | Token ID:  27513 | Token: 'Ä ink'\n",
      "060 | Token ID:     11 | Token: ','\n",
      "061 | Token ID:    323 | Token: 'Ä and'\n",
      "062 | Token ID:   5829 | Token: 'Ä uses'\n",
      "063 | Token ID:    264 | Token: 'Ä a'\n",
      "064 | Token ID:   2678 | Token: 'Ä small'\n",
      "065 | Token ID:   5041 | Token: 'Ä ball'\n",
      "066 | Token ID:    311 | Token: 'Ä to'\n",
      "067 | Token ID:   8481 | Token: 'Ä transfer'\n",
      "068 | Token ID:  27513 | Token: 'Ä ink'\n",
      "069 | Token ID:    311 | Token: 'Ä to'\n",
      "070 | Token ID:   5684 | Token: 'Ä paper'\n",
      "071 | Token ID:    374 | Token: 'Ä is'\n",
      "072 | Token ID:    264 | Token: 'Ä a'\n",
      "073 | Token ID:   5041 | Token: 'Ä ball'\n",
      "074 | Token ID:   2837 | Token: 'point'\n",
      "075 | Token ID:   5869 | Token: 'Ä pen'\n",
      "076 | Token ID:  16045 | Token: \".',\"\n",
      "077 | Token ID:      8 | Token: ')'\n",
      "078 | Token ID: 128009 | Token: '<|eot_id|>'\n",
      "079 | Token ID: 128006 | Token: '<|start_header_id|>'\n",
      "080 | Token ID:  78191 | Token: 'assistant'\n",
      "081 | Token ID: 128007 | Token: '<|end_header_id|>'\n",
      "082 | Token ID:    271 | Token: 'ÄŠÄŠ'\n",
      "083 | Token ID:  22447 | Token: 'Ã¢Äª'\n",
      "084 | Token ID:    222 | Token: 'Ä¢'\n",
      "085 | Token ID:     87 | Token: 'x'\n",
      "086 | Token ID:    320 | Token: 'Ä ('\n",
      "087 | Token ID:  40413 | Token: 'Writing'\n",
      "088 | Token ID:  57424 | Token: 'Instrument'\n",
      "089 | Token ID:   2120 | Token: '(x'\n",
      "090 | Token ID:      8 | Token: ')'\n",
      "091 | Token ID:  75078 | Token: 'Ä Ã¢ÄªÂ§'\n",
      "092 | Token ID:  70722 | Token: 'Ä Thin'\n",
      "093 | Token ID:     34 | Token: 'C'\n",
      "094 | Token ID:   4010 | Token: 'yl'\n",
      "095 | Token ID:  63506 | Token: 'indrical'\n",
      "096 | Token ID:   5561 | Token: 'Body'\n",
      "097 | Token ID:   2120 | Token: '(x'\n",
      "098 | Token ID:      8 | Token: ')'\n",
      "099 | Token ID:  75078 | Token: 'Ä Ã¢ÄªÂ§'\n",
      "100 | Token ID:  31911 | Token: 'Ä Contains'\n",
      "101 | Token ID:    644 | Token: 'In'\n",
      "102 | Token ID:     74 | Token: 'k'\n",
      "103 | Token ID:   2120 | Token: '(x'\n",
      "104 | Token ID:      8 | Token: ')'\n",
      "105 | Token ID:  75078 | Token: 'Ä Ã¢ÄªÂ§'\n",
      "106 | Token ID:  39923 | Token: 'Ä Uses'\n",
      "107 | Token ID:  26375 | Token: 'Small'\n",
      "108 | Token ID:  37007 | Token: 'Ball'\n",
      "109 | Token ID:   2120 | Token: '(x'\n",
      "110 | Token ID:      8 | Token: ')'\n",
      "111 | Token ID:  75078 | Token: 'Ä Ã¢ÄªÂ§'\n",
      "112 | Token ID:   4149 | Token: 'Ä Trans'\n",
      "113 | Token ID:  50893 | Token: 'fers'\n",
      "114 | Token ID:    644 | Token: 'In'\n",
      "115 | Token ID:     74 | Token: 'k'\n",
      "116 | Token ID:   1271 | Token: 'To'\n",
      "117 | Token ID:  31998 | Token: 'Paper'\n",
      "118 | Token ID:   2120 | Token: '(x'\n",
      "119 | Token ID:      8 | Token: ')'\n",
      "120 | Token ID:  11651 | Token: 'Ä Ã¢Ä¨Ä´'\n",
      "121 | Token ID:  13131 | Token: 'Ä Ball'\n",
      "122 | Token ID:   2837 | Token: 'point'\n",
      "123 | Token ID:  29305 | Token: 'Pen'\n",
      "124 | Token ID:   2120 | Token: '(x'\n",
      "125 | Token ID:    595 | Token: '))'\n",
      "126 | Token ID: 128009 | Token: '<|eot_id|>'\n"
     ]
    }
   ],
   "source": [
    "text = dataset[0]['text']\n",
    "tokenized = tokenizer(text, return_tensors=\"pt\", return_attention_mask=True)\n",
    "input_ids = tokenized[\"input_ids\"][0]\n",
    "\n",
    "decoded_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "for i, (token_id, token_str) in enumerate(zip(input_ids, decoded_tokens)):\n",
    "    print(f\"{i:03d} | Token ID: {token_id.item():>6} | Token: {repr(token_str)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addestramento del modello tramite LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:43:45.412171Z",
     "iopub.status.busy": "2025-05-10T13:43:45.411395Z",
     "iopub.status.idle": "2025-05-10T13:43:50.131201Z",
     "shell.execute_reply": "2025-05-10T13:43:50.130223Z",
     "shell.execute_reply.started": "2025-05-10T13:43:45.412148Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bac46b5539b4fb184ad92b7f1fe9514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class LossLoggerCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs and \"loss\" in logs:\n",
    "            loss = logs[\"loss\"]\n",
    "            step = state.global_step\n",
    "            self.train_losses.append((step, loss))\n",
    "            print(f\"ðŸ“‰ Step {step} - Loss: {loss:.4f}\")\n",
    "\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "loss_callback = LossLoggerCallback()\n",
    "\n",
    "#model.config.use_cache = False\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    do_train                    = True,\n",
    "\n",
    "    dataset_text_field          = \"text\",\n",
    "    per_device_train_batch_size = 2,\n",
    "    gradient_accumulation_steps = 8,\n",
    "\n",
    "    num_train_epochs            = 3,   # Epoche complete\n",
    "    #max_steps                   = 10,\n",
    "    \n",
    "    learning_rate               = 2e-4,\n",
    "    lr_scheduler_type           = \"linear\",\n",
    "    logging_strategy            = 'steps',\n",
    "    logging_steps               = 20,\n",
    "    # ðŸ’¾ Salvataggio\n",
    "    save_strategy               = 'epoch',\n",
    "    #save_steps                  = 200,\n",
    "\n",
    "    warmup_steps                = 40,\n",
    "\n",
    "    optim                       = \"adamw_8bit\",\n",
    "    seed                        = 42,\n",
    "\n",
    "    fp16                        = not is_bfloat16_supported(),\n",
    "    bf16                        = is_bfloat16_supported(),\n",
    "\n",
    "    weight_decay                = 0.01,\n",
    "    report_to                   = \"none\",\n",
    ")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'left'\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model              = model,\n",
    "    tokenizer          = tokenizer,\n",
    "    dataset_num_proc   = 2,\n",
    "    max_seq_length     = MAX_SEQ_LENGTH,\n",
    "    train_dataset      = dataset,\n",
    "    args               = training_args,\n",
    "    data_collator      = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    packing            = False,\n",
    "    callbacks          = [loss_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:43:53.830711Z",
     "iopub.status.busy": "2025-05-10T13:43:53.829893Z",
     "iopub.status.idle": "2025-05-10T13:44:04.637114Z",
     "shell.execute_reply": "2025-05-10T13:44:04.635909Z",
     "shell.execute_reply.started": "2025-05-10T13:43:53.830682Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 10,000 | Num Epochs = 3 | Total steps = 936\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 8 x 1) = 32\n",
      " \"-____-\"     Trainable parameters = 24,313,856/3,000,000,000 (0.81% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avvio addestramento LoRA...\n",
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/1163210804.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Avvio addestramento LoRA...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n",
      "\u001b[0;32m/kaggle/working/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         outputs = super().compute_loss(\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_pre_compute_loss\u001b[0;34m(self, model, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1034\u001b[0m         )\n\u001b[1;32m   1035\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3799\u001b[0m                 \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3801\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3802\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mPeftModelForCausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m ):\n\u001b[0;32m-> 1207\u001b[0;31m     return self.base_model(\n\u001b[0m\u001b[1;32m   1208\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0mcausal_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_injection_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0mshift_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0;31m# shift_labels = torch.hstack((labels[..., 1:], self.extra_ignored_labels[:labels.shape[0]]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m             loss = fast_cross_entropy_loss(\n\u001b[0m\u001b[1;32m   1149\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshift_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/kernels/cross_entropy_loss.py\u001b[0m in \u001b[0;36mfast_cross_entropy_loss\u001b[0;34m(logits, labels, logit_softcapping, logit_scaling, n_items)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m def fast_cross_entropy_loss(\n\u001b[0m\u001b[1;32m    386\u001b[0m     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Avvio addestramento LoRA...\")\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvataggio del modello e visualizzazione della loss di addestramento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T10:49:46.044263Z",
     "iopub.status.busy": "2025-05-10T10:49:46.043627Z",
     "iopub.status.idle": "2025-05-10T10:49:46.255531Z",
     "shell.execute_reply": "2025-05-10T10:49:46.254820Z",
     "shell.execute_reply.started": "2025-05-10T10:49:46.044239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mkdir $SAVE_DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T10:55:53.743230Z",
     "iopub.status.busy": "2025-05-10T10:55:53.742945Z",
     "iopub.status.idle": "2025-05-10T10:55:53.812392Z",
     "shell.execute_reply": "2025-05-10T10:55:53.811441Z",
     "shell.execute_reply.started": "2025-05-10T10:55:53.743208Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# PUSH MODELLO LoRA + TOKENIZER su HUGGING FACE\n",
    "print(\"ðŸ”„ Caricamento del modello e del tokenizer in corso...\")\n",
    "model.push_to_hub(OUTPUT_REPO, token=HF_UNIVERSAL_TOKEN, private=True)\n",
    "tokenizer.push_to_hub(OUTPUT_REPO, token=HF_UNIVERSAL_TOKEN, private=True)\n",
    "\n",
    "print(f\"âœ… Modello caricato correttamente su: {OUTPUT_REPO}\\n\")\n",
    "print(f\"âœ… Tokenizer caricato correttamente su: {OUTPUT_REPO}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T10:50:26.486446Z",
     "iopub.status.busy": "2025-05-10T10:50:26.486167Z",
     "iopub.status.idle": "2025-05-10T10:50:27.868676Z",
     "shell.execute_reply": "2025-05-10T10:50:27.867800Z",
     "shell.execute_reply.started": "2025-05-10T10:50:26.486426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# SALVATAGGIO MODELLO LoRA + TOKENIZER\n",
    "print(\"ðŸ’¾ Salvataggio del modello e tokenizer...\")\n",
    "trainer.model.save_pretrained(SAVE_DIRECTORY)\n",
    "tokenizer.save_pretrained(SAVE_DIRECTORY)\n",
    "print(f\"âœ… Modello LoRA salvato in: {SAVE_DIRECTORY}\")\n",
    "\n",
    "#Visualizzazione loss di addestramento\n",
    "def crate_loss_chart(json_file):\n",
    "    # Carica il file JSON\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Estrai i dati di interesse\n",
    "    log_history = data.get(\"log_history\", [])\n",
    "    steps = [entry[\"step\"] for entry in log_history]\n",
    "    losses = [entry[\"loss\"] for entry in log_history]\n",
    "    \n",
    "    # Crea un DataFrame\n",
    "    df = pd.DataFrame({\"Step\": steps, \"Loss\": losses})\n",
    "    \n",
    "    # Crea il grafico a linee\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(data=df, x=\"Step\", y=\"Loss\", marker='o')\n",
    "    plt.title(\"Andamento della Loss\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    \n",
    "    # Rotazione delle etichette e selezione dei ticks\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.locator_params(axis='x', nbins=10)  # Mostra solo 10 ticks sull'asse x\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()  # Migliora la disposizione degli elementi\n",
    "    plt.show()\n",
    "\n",
    "loss_path = \"/kaggle/working/trainer_output/checkpoint-936/trainer_state.json\"\n",
    "crate_loss_chart(loss_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
